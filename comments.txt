Привет, Артем!
Спасибо за оперативное и очень подробное ревью кода!
Я поправил часть замечаний, но думаю, что мы еще продолжим работу над проектом)

--------

Комментарий к functional.py

О радианах: я перенес решение этой проблемы на этап формирования stage
в файле download_data.py две функции собирают датафрейм событий и данные по городам
events_data = data_of_research(base_url, events_base_path, date=date, depth=depth, spark_session=spark_session) \
        .select('event', 'event_type', 'date', radians(col('lat')).alias('lat'), radians(col('lon')).alias('lon')) \
        .sample(fraction=0.01, seed=3000)

cities = spark.read.option("delimiter", ";").option("header", "true").schema(cities_schema).csv(
        base_url + '/user/yarruss12/data/geo.csv') \
        .withColumn('city_long', radians(regexp_replace(F.col("lng"), ',', '.').cast(DoubleType()))) \
        .withColumn('city_lat', radians(regexp_replace(F.col("lat"), ',', '.').cast(DoubleType()))) \
        .select('id', 'city', 'city_lat', 'city_long')

Поэтому на этапе работы с данными сведения о геолокации сообщений и городов уже переведены в радианы.
Впрочем, если в будущем эти данные потребуются именно как координаты, то я перенесу расчет в функцию distance
файла functional.py

--------
Комментарий к first_view

Функции travel_counter, travel_cities_list объединил в функцию travel_cities, в которой определяю список городов, а потом определяю длинну списка
Формирую группу как в стате хабра, потом проверяю предыдущий город с текущим и удаляю повторы

Переделал actual_home_finder, добавив к нему расчет местного времени
За основу взял время сообщений, так как это единственное поле (вроде как) в котором есть время. убрал пустые значения
Через udf присвоил значение utc и на его основе расчитал местное время, может не самое элегантное и производительное,
но удобное и гибкое решение

Переделал homecity_finder
Предлагаемое решение очень интересное, сам бы я до него не дошел, но
как мне кажется оно подходит, когда оцениваешь непрерывный каждодневный поток сообщений,
В нашем случае расчитывать group_id и day_num недостаточно, если между текущим днем и предыдущим нет сообщений,
то мы получим кучу строк по одному пользователю который писал 1 сообщение раз в 2 дня, из одного и того же города
поэтому расчитав group_id, я сравнивал текущий город с предыдущим по лагу города с сортировкой по group_id
Потом находил для user_id, city максимальное и минимальное время, схлопывал их и находил разность самой ранней и самой поздней даты
.withColumn('all_days', expr("case when city = privious_city then datediff(mmax , mmin) else 0 end"))
если разность > 26 то запись нам подходит

При этом в уме мы держим установку, что нам не нужны записи по которым невозможно определить домашний город пользователя

Хотя наверное в проме есть вьюха со всеми домашними адресами, к которой можно обратиться если ничего не найдено

--------
Комментарий к second_view
В stage создана отдельное представление с пулом id и датой первого входа
Перед каждым запуском функции second_view табилца дополняется новыми данными, правда у меня возникла проблема
Интерпретатор требует обноаить таблицу перед перезаливкой, а моих знаний тут не хватает
spark.catalog.refreshTable("old_users") # Не совсем верно

Разбивку по месяцам и неделям сделал через date_trunc и trunc


--------
Комментарий к third_view


Надеюсь я верно понял твое предложение
Моя первоначальная задумка  была создать пул всех пар отправитель(left_user)-получатель и пар получатель(left_user)-отправитель
И при соединении leftanti будут исключены все записи где совпадает left_user, но видимо я не правильно расчитал последний шаг
Внес изменения. заменив left_join на union. По прежнему все отправители и получатели слева, а их собеседники - справа
А при соединении с выбокой подписчиков использован leftanti как рекомендовалось, но
Появляется проблема с определением локального времени оставшихся пользователей, если я правильно понимаю, то остаются только подписчики
Их мы формировали по event.event_type = 'subscribers' у которых message_ts is null, колонка datetime дает только дату
Вопрос: как будем выходить из ситуации?

