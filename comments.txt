Привет, Артем!
Спасибо за оперативное и очень подробное ревью кода!
Я поправил часть замечаний, но думаю, что мы еще продолжим работу над проектом)

--------

Комментарий к functional.py

Касаемо радиан: я перенес решение этой проблемы на этап формирования stage
в файле download_data.py две функции собирают датафрейм событий и данные по городам
events_data = data_of_research(base_url, events_base_path, date=date, depth=depth, spark_session=spark_session) \
        .select('event', 'event_type', 'date', radians(col('lat')).alias('lat'), radians(col('lon')).alias('lon')) \
        .sample(fraction=0.01, seed=3000)

cities = spark.read.option("delimiter", ";").option("header", "true").schema(cities_schema).csv(
        base_url + '/user/yarruss12/data/geo.csv') \
        .withColumn('city_long', radians(regexp_replace(F.col("lng"), ',', '.').cast(DoubleType()))) \
        .withColumn('city_lat', radians(regexp_replace(F.col("lat"), ',', '.').cast(DoubleType()))) \
        .select('id', 'city', 'city_lat', 'city_long')

Поэтому на этапе преобразований данные о геолокации сообщений и городов уже переведены в радианы.
Впрочем, если в будущем эти данные потребуются именно как координаты, то я перенесу расчет в функцию distance
файла functional.py

--------

Комментарий к first_view
Переделал actual_home_finder, travel_counter, travel_cities_list

при определении домашнего города не ясно как обрабатывать ситуацию, когда сообщения отправляются не каждый день и соответственно временная нить прерывается
Например
|user_id|       city|      date|rank|  group_id|
+-------+-----------+----------+----+----------+
| 21395|     Mackay|2022-05-23|   1|2022-05-22|
|  21395|     Mackay|2022-05-15|   2|2022-05-13|
|  21395|     Mackay|2022-05-09|   3|2022-05-06|
|  21395|     Mackay|2022-05-04|   4|2022-04-30|
|  21395|     Mackay|2022-05-03|   5|2022-04-28|
|  21395|     Mackay|2022-05-02|   6|2022-04-26|
|  21395|     Mackay|2022-04-27|   7|2022-04-20|
|  21395|     Mackay|2022-04-27|   8|2022-04-19|
|  21395|     Mackay|2022-04-27|   9|2022-04-18|

Прерывающиеся данные сгрупированные только по user_id
.groupBy("user_id").agg(collect_list('city'))
Дают следующий результат
21395  |[Mackay, Mackay, Mackay, Mackay, Mackay, Mackay, Mackay, Mackay, Mackay]
Сгруппированные по user_id и group_id
.groupBy("user_id", "group_id").agg(collect_list('city'))

|21395  |2022-04-18|[Mackay]            |
|21395  |2022-04-19|[Mackay]            |
|21395  |2022-04-20|[Mackay]            |
|21395  |2022-04-26|[Mackay]            |
|21395  |2022-04-28|[Mackay]            |
|21395  |2022-04-30|[Mackay]            |
|21395  |2022-05-06|[Mackay]            |
|21395  |2022-05-13|[Mackay]            |
|21395  |2022-05-22|[Mackay]            |

Определ механиз вычленения localtime

Возможно стоит решить проблему через lag
 .withColumn('lag', lag('group_id', 1).over(Window.partitionBy("user_id").orderBy(desc("group_id"))))
Но что дальше - я затрудняюсь


--------

Комментарий к second_view
Сообщение о первой регистрации
Нужно создать в stage отдельное представление с пулом id и датой первого входа, если записи нет, то добавлять из текущих данных

Разбивку по месяцам и неделям сделал через date_trunc


Комментарий к third_view

"Таким образом останутся те пользователи, которые кому-то писали, но которым никогда не писали, независимо от собеседника.
Предлагаю пойти немного другим путём: взять все варианты переписывавшихся пользователей (как если бы они были как получателями,
так и отправителями), и уже с этими парами сделать laftanti от пользователей из all_subscribers_area".

Надеюсь я верно понял твое предложение
Моя задумка была создать пул всех пар отправитель(left_user)-получатель и пар получатель(left_user)-отправитель
И при соединении leftanti будут исключены все записи где совпадает left_user, но видимо я не правильно расчитал последний шаг
Внес изменения. заменив left_join на union. По прежнему все отправители и получатели слева, а их собеседники - справа
А при соединении с выбокой подписчиков использован leftanti


